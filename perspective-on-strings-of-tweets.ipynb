{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "from googleapiclient import discovery\n",
    "from langdetect import detect\n",
    "import json,requests,re,os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_keys_path = \"/etc/twitter-api-key.csv\"\n",
    "google_api_keys_path = \"google-api-key.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "## twitter\n",
    "creds = pd.read_csv(twitter_keys_path)\n",
    "consumer_key = creds['consumer_key'][0]\n",
    "consumer_secret = creds['consumer_secret'][0]\n",
    "access_key = creds['access_token'][0]\n",
    "access_secret = creds['access_token_secret'][0]\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "## google api\n",
    "API_KEY = pd.read_csv(google_api_keys_path)['google-key'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for stringing tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TWEET_BATCH_NUM = 3\n",
    "PERSPECTIVE_MODELS = ['TOXICITY', 'IDENTITY_ATTACK', 'INSULT', 'PROFANITY','THREAT','SEXUALLY_EXPLICIT', 'FLIRTATION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOXICITY\n",
      "IDENTITY_ATTACK\n",
      "INSULT\n",
      "PROFANITY\n",
      "THREAT\n",
      "SEXUALLY_EXPLICIT\n",
      "FLIRTATION\n"
     ]
    }
   ],
   "source": [
    "models_setting_json = {}\n",
    "for model in PERSPECTIVE_MODELS:\n",
    "    print(model)\n",
    "    models_setting_json[model] = {'scoreThreshold': '0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_user_timeline(screenName, tweetCount):\n",
    "    statuses = api.user_timeline(screen_name = screenName,count=tweetCount, tweet_mode=\"extended\")\n",
    "    tweet_info = {}\n",
    "    for tweet in statuses:\n",
    "        if hasattr(tweet, 'retweeted_status'):\n",
    "            tweet_info[tweet.id] = {'text': tweet.retweeted_status.full_text, 'tweet_time': tweet.created_at}\n",
    "        else:\n",
    "            tweet_info[tweet.id] = {'text': tweet.full_text, 'tweet_time': tweet.created_at}\n",
    "\n",
    "    return tweet_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_tweets(tweets):\n",
    "    cleaned_tweets = []\n",
    "    for tweet_id, tweet in tweets.items():\n",
    "        try:\n",
    "            if(detect(tweet['text']) == 'en'):\n",
    "                cleaned_tweet = re.sub(r'(@\\S+)|(http\\S+)', \" \", str(tweet['text']))\n",
    "                if(cleaned_tweet and cleaned_tweet.strip()):\n",
    "                    cleaned_tweets.append({'cleaned_tweet': cleaned_tweet, \n",
    "                                           'original_tweet': tweet['text'],\n",
    "                                           'tweet_time': tweet['tweet_time']})\n",
    "        except Exception as e:\n",
    "#             print('Exception wheen cleaning- Tweet in response: ' + tweet['text'])\n",
    "            print(e)\n",
    "    print(len(cleaned_tweets))\n",
    "    return cleaned_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## string the tweets together!\n",
    "def get_batched_tweets(tweets):\n",
    "    cleaned_user_timeline_tweets = clean_tweets(tweets)\n",
    "    batched_tweets = []\n",
    "    if len(cleaned_user_timeline_tweets) > TWEET_BATCH_NUM:\n",
    "        each_batch_size = int(len(cleaned_user_timeline_tweets)/TWEET_BATCH_NUM)\n",
    "        for i in range(0, TWEET_BATCH_NUM):\n",
    "            batched_tweets.append(cleaned_user_timeline_tweets[i*each_batch_size : (i+1)*each_batch_size])\n",
    "    else:\n",
    "        batched_tweets = cleaned_user_timeline_tweets\n",
    "    return batched_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_user_perspective_score(batched_tweets, models_setting_json, twitter_account):\n",
    "    # need to add multiple keys\n",
    "    service = discovery.build('commentanalyzer', 'v1alpha1', developerKey=API_KEY,  cache_discovery=False)\n",
    "    tweets_with_perspective_scores = []\n",
    "    tweet_count = 0\n",
    "\n",
    "    # where we finally store the scores\n",
    "    user_perspective_scores_json = {}\n",
    "    temp_scores = {}\n",
    "    for model in PERSPECTIVE_MODELS:\n",
    "        temp_scores[model] = []\n",
    "\n",
    "    for i in range(0, TWEET_BATCH_NUM):\n",
    "        tweet_string = ''\n",
    "        for tweet in batched_tweets[i]:\n",
    "            tweet_string += tweet['cleaned_tweet'] + '\\n'\n",
    "            tweet_string = tweet_string.encode('utf-8')\n",
    "\n",
    "        print('length: ' + str(len(tweet_string)))\n",
    "\n",
    "        analyze_request = {\n",
    "                        'comment': { 'text': tweet_string},\n",
    "                        'requestedAttributes': models_setting_json}\n",
    "        try:\n",
    "            response = service.comments().analyze(body=analyze_request).execute()\n",
    "            # print(response)\n",
    "            if(response['attributeScores']):\n",
    "                for model in PERSPECTIVE_MODELS:\n",
    "                    if model in response['attributeScores']:\n",
    "                        temp_scores[model].append(response['attributeScores'][model]['summaryScore']['value'])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('Exception when getting perspective scores ' + twitter_account)\n",
    "            print(len(tweet_string))\n",
    "\n",
    "    for model in PERSPECTIVE_MODELS:\n",
    "        if len(temp_scores[model]) > 0:\n",
    "            print(temp_scores[model])\n",
    "            user_perspective_scores_json[model] = sum(temp_scores[model])/len(temp_scores[model])\n",
    "            print(user_perspective_scores_json[model])\n",
    "        else:\n",
    "            user_perspective_scores_json[model] = None\n",
    "\n",
    "\n",
    "    return user_perspective_scores_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_account = 'im__jane'\n",
    "TWEET_NUM = 200\n",
    "\n",
    "tweets = get_user_timeline(twitter_account, TWEET_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ascii' codec can't encode character u'\\u2019' in position 8: ordinal not in range(128)\n",
      "'ascii' codec can't encode character u'\\u2019' in position 235: ordinal not in range(128)\n",
      "'ascii' codec can't encode characters in position 49-52: ordinal not in range(128)\n",
      "'ascii' codec can't encode character u'\\u2019' in position 76: ordinal not in range(128)\n",
      "'ascii' codec can't encode characters in position 1-11: ordinal not in range(128)\n",
      "'ascii' codec can't encode characters in position 111-112: ordinal not in range(128)\n",
      "'ascii' codec can't encode characters in position 176-177: ordinal not in range(128)\n",
      "'ascii' codec can't encode characters in position 68-69: ordinal not in range(128)\n",
      "'ascii' codec can't encode character u'\\u2019' in position 116: ordinal not in range(128)\n",
      "'ascii' codec can't encode characters in position 27-28: ordinal not in range(128)\n",
      "'ascii' codec can't encode characters in position 194-195: ordinal not in range(128)\n",
      "'ascii' codec can't encode characters in position 184-185: ordinal not in range(128)\n",
      "'ascii' codec can't encode characters in position 29-38: ordinal not in range(128)\n",
      "'ascii' codec can't encode characters in position 119-120: ordinal not in range(128)\n",
      "'ascii' codec can't encode character u'\\u2019' in position 88: ordinal not in range(128)\n",
      "'ascii' codec can't encode characters in position 130-131: ordinal not in range(128)\n",
      "'ascii' codec can't encode characters in position 46-47: ordinal not in range(128)\n",
      "'ascii' codec can't encode characters in position 78-81: ordinal not in range(128)\n",
      "'ascii' codec can't encode characters in position 21-22: ordinal not in range(128)\n",
      "'ascii' codec can't encode characters in position 90-93: ordinal not in range(128)\n",
      "'ascii' codec can't encode character u'\\u2022' in position 61: ordinal not in range(128)\n",
      "'ascii' codec can't encode characters in position 116-117: ordinal not in range(128)\n",
      "'ascii' codec can't encode characters in position 126-127: ordinal not in range(128)\n",
      "'ascii' codec can't encode characters in position 34-35: ordinal not in range(128)\n",
      "'ascii' codec can't encode characters in position 174-175: ordinal not in range(128)\n",
      "'ascii' codec can't encode characters in position 35-36: ordinal not in range(128)\n",
      "'ascii' codec can't encode character u'\\u2019' in position 4: ordinal not in range(128)\n",
      "'ascii' codec can't encode character u'\\u201c' in position 16: ordinal not in range(128)\n",
      "'ascii' codec can't encode character u'\\u201c' in position 167: ordinal not in range(128)\n",
      "'ascii' codec can't encode characters in position 42-43: ordinal not in range(128)\n",
      "'ascii' codec can't encode characters in position 54-55: ordinal not in range(128)\n",
      "'ascii' codec can't encode character u'\\u2019' in position 34: ordinal not in range(128)\n",
      "'ascii' codec can't encode character u'\\u2019' in position 39: ordinal not in range(128)\n",
      "'ascii' codec can't encode characters in position 53-56: ordinal not in range(128)\n",
      "'ascii' codec can't encode character u'\\u201c' in position 47: ordinal not in range(128)\n",
      "'ascii' codec can't encode character u'\\u2019' in position 14: ordinal not in range(128)\n",
      "'ascii' codec can't encode characters in position 101-102: ordinal not in range(128)\n",
      "'ascii' codec can't encode characters in position 23-26: ordinal not in range(128)\n",
      "No features in text.\n",
      "'ascii' codec can't encode character u'\\u2014' in position 57: ordinal not in range(128)\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "batched_tweets = get_batched_tweets(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: 3056\n",
      "length: 3627\n",
      "length: 4196\n",
      "[0.18453915, 0.23787954, 0.3217358]\n",
      "0.248051496667\n",
      "[0.25080234, 0.35056716, 0.38586828]\n",
      "0.32907926\n",
      "[0.21692717, 0.25511935, 0.30610135]\n",
      "0.259382623333\n",
      "[0.1577357, 0.1489321, 0.22514658]\n",
      "0.17727146\n",
      "[0.212965, 0.2665316, 0.3757453]\n",
      "0.285080633333\n",
      "[0.3035996, 0.15463679, 0.31295457]\n",
      "0.257063653333\n",
      "[0.46974406, 0.47966555, 0.4480788]\n",
      "0.46582947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'FLIRTATION': 0.46582947,\n",
       " 'IDENTITY_ATTACK': 0.32907926000000004,\n",
       " 'INSULT': 0.25938262333333334,\n",
       " 'PROFANITY': 0.17727146000000002,\n",
       " 'SEXUALLY_EXPLICIT': 0.2570636533333333,\n",
       " 'THREAT': 0.28508063333333333,\n",
       " 'TOXICITY': 0.24805149666666668}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_user_perspective_score(batched_tweets, models_setting_json, twitter_account)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
